\section{A model for eye information}
This section introduces a probabilistic model for understanding \emph{eye processing systems}. An eye processing system is any software and/or hardware system which uses eye image capture to extract information about its subjects. It therefore covers both gaze estimation and iris recognition. The purpose of the proposed model is to allow reinterpretation of gaze estimation, iris recognition, and potentially other eye information processes under a common frame of reference. This makes it easier to understand how potentially conflicting goals such as iris obfuscation and gaze estimation interact and what trade-offs between them are likely to occur. Our hope is that the model will be used as a point of reference and comparison for future studies in this field.

%This allows analysis of how different goals affect each other. In the context of this paper, it specifically provides a framework for understanding how 

%This section presents a model and a methodology for understanding eye information processes. 
%This section presents an overview of the model used throughout the paper to examine the processes of iris recognition and gaze estimation from a common frame of reference. This allows critical analysis 





%This section presents a model for understanding how information flows through such systems and how image manipulations affect the information measurement processes. This allows us to evaluate and compare the obfuscation methods from a purely theoretical perspective which ... \todo{Overvej integration.. hvad giver det her? }

Any eye processing system has the goal of accurately measuring some properties of the real world through capture of eye images. These properties are encoded through physical processes as signals which are transformed and processed with the goal of isolating the property of interest from everything else. The systems therefore essentially have the function of signal denoising, albeit rather aggressively because anything but the target property is considered noise. Similarly, eye processing systems comprise a communication channel pipeline, with each physical encoding, image capturing, or transformation process forming a component in the pipeline. We propose a probabilistic graphical model which allows interpretations from both perspectives. 

%Similarly, information theory lets us define image processing as a communication system and analyse how uncertainty propagates and is added from noise. This lets us evaluate the effect of obfuscation methods directly on the image data. Although this is not in itself enough to demonstrate the effectiveness of the proposed methods, it creates a reference frame that does not depend on specific implementations of any algorithms. We propose a model which allows useful interpretations from both points of view and which has a simple graphical representation (shown in \autoref{fig:model}).

\begin{figure}
    \centering
    \begin{tikzpicture}[node distance=1.3cm]
        \node (q1) [] {$Q_1$};
        \node (qd) [right of=q1] {$\dots$};
        \node (qn) [right of=qd] {$Q_n$};
        \node (t1) [align=right, left of=q1] {(1)};
        
        %\node (e1) [rect, below of=q1] {$f_e^{(1)}$};
        %\node (ed) [right of=e1] {$\dots$};
        %\node (en) [rect, right of=ed] {$f_e^{(n)}$};
        %\node (t2) [align=right, left of=e1] {(2)};
        
        
        %\draw [arrow] (q1) -- (e1);
        %\draw [arrow] (qn) -- (en);
        
        \node (c) [rect, below of=qd] {$f_e$};
        \node (t3) [align=right, below of=t1] {(3)};
        \draw [arrow] (q1) -- (c);
        \draw [arrow] (qn) -- (c);
        
        \node (f1) [rect, below of=c] {$f_p$};
        \node (fd) [below of=f1] {$\dots$};
        \node (fn) [rect, below of=fd] {$f_n$};
        \draw [arrow] (c) -- node[anchor=east] {I} (f1);
        \draw [arrow] (f1) -- (fd);
        \draw [arrow] (fd) -- (fn);
        
        \node (t4) [align=right, below of=t3] {(4)};
        
        \node (dd) [below of=fn] {$\dots$};
        \node (d1) [rect, left of=dd] {$f_d^{(1)}$};
        \node (dn) [rect, right of=dd] {$f_d^{(n)}$};
        \node (t5) [align=right, left of= d1] {(5)};
        
        \draw [arrow] (fn) -- node[anchor=south east] {$I^*$} (d1);
        \draw [arrow] (fn) -- node[anchor=south west] {$I^*$} (dn);
        
        \node (r1) [below of=d1] {$R_1$};
        \node (rd) [right of=r1] {$\dots$};
        \node (rn) [right of=rd] {$R_n$};
        
        \draw [arrow] (d1) -- (r1);
        \draw [arrow] (dn) -- (rn);
    \end{tikzpicture}
    
    \caption{Eye information processing model: (1) Input properties. (2) Functions that encode the physical manifestation and uncertainties of the source properties. (3) Image capturing process. (4) Image processing steps which may typically be described as a single function. (5) Decoding functions that aim to extract original properties, e.g. an iris pattern or gaze direction.}
    \label{fig:model}
\end{figure}


%We define a model that allows easy analysis from both a signal-processing centric and probability centric view. 

Let an eye information processing system be defined by $\Lambda = \{Q, R, f_e, \mathcal{D}, \mathcal{P}\}$, where $Q=\{Q_1, \dots, Q_n\}$ is a set of source properties, $R=\{R_1,\dots,R_n\}$ is a set of output properties, $f_e$ is an encoding function, $\mathcal{D}=\{f_d^{(1)}, \dots, f_d^{(n)}\}$ is a set of decoding functions, and $\mathcal{P}=\{f_p^{(1)}, \dots, f_p^{(n)}\}$ is a set of processing functions. A graphical representation is shown in \autoref{fig:model}. The encoding functions in $f_e$ represent how properties are manifested as physical quantities and captured by a camera. This simplification retains the modelling of uncertainty in both processes. The results are given as $R_i = (f_d^{(i)}\circ f_p)(\hat{Q})$. To encode noise and information loss, all properties and functions are viewed as discrete signals composed of random samples of some distribution. The terms signal and property are therefore used interchangeably throughout this text.

%To show this, note that a graph is defined by $G=\{V, E\}$ which in this model is given by $V = Q\cup R\cup \hat{Q}$ and $E = \mathcal{E}\cup \mathcal{D}\cup \mathcal{P}$. %It will not, however, be used to infer conditional probabilities but, as stated earlier, to understand how uncertainty propagates through the system.

%The purpose of the model is to make inquiries about decoding uncertainties and signal correlations intuitive and generalisable. For example, the noise resulting from an iris encoding is given by $P_{R_{iris}|Q_{iris}}$


\paragraph{Model analysis}
This section presents some fundamental definitions from information theory and signal processing that are necessary to describe and analyse iris recognition, gaze estimation, and iris obfuscation from the perspective of the graphical model.

Information theory enables precise definitions for the uncertainties retained and introduced at all parts of the presented model. The base measure is entropy, denoted $H$ which defines the optimal average encoding length of symbols $x_i$ drawn from a discrete distribution $X$ defined by
\begin{align}
    H(X) = -\sum_{x\in \mathcal{X}} p(x)\log_2p(x),
\end{align}
with results in the units of bits. Different bases may be used for alternate units. A uniformly distributed random variable has the maximum entropy for its number of states, precisely $\log{N}$. In terms of iris recognition, the entropy of code symbols (bits are typically used) can be used to calculate the expected amount of information present in the entire signal. For example, Daugman calculated the expected iris code entropy by fitting a binomial distribution to the iris code distance comparisons, which revealed an approximate 250 bits of information between codes (REF). This entropy only accounts for the information content in the final codes and thus does not account for noise added during the encoding and processing steps. 

Mutual information is a measure that defines exactly how much entropy is preserved over a communications channel and is thus useful for determining how much information is actually captured by a specific process. Its definition is 
\begin{align}
    I(Y;X) = \sum_{x\in \mathcal{X}, y\in \mathcal{Y}} P_{X,Y}(x, y)\log_2 \frac{P_{X,Y}(x, y)}{P_{X}(x)P_{Y}(y)} = H(Y) + H(Y|X),
\end{align}
where $H(Y|X)$ is the conditional entropy which is a measure of the error added by the communication channel.

\begin{align}\label{eq:entropy-law}
    H(X) = I(Y;X)+H(Y|X)
\end{align}

For iris obfuscation, the goal is to minimise $I(R_{iris}, Q_{iris})$ and maximise $I(R_{gaze}, Q_{gaze})$. Measuring these directly is again not possible as the $Q$ signals are not the measured signals. The only known information source is the image $I$ where the two signals have been combined into a single signal. However, because $H(Q_{gaze})$ should be very low, i.e. it represents an encoding of just two decimal values, the mutual information between the original and obfuscated images $I(I, I^*)$ can be used as a proxy to measure the level of obfuscation. Additionally, for any set of signals $X, Y, Z$ where $Z = f_z(Y)$ and $Y= f_z(X)$, then $I(Z; Y) \leq I(Z;X)$ (REF to proof). Thus, it is an upper bound for the mutual information which makes the results much more useful.

Finally, the notion of channel capacity is used to define the maximum mutual information of a communications channel for any input distribution. It is defined as
\begin{align}
    C = \sup_{p(x)} I(X, Y).
\end{align}
The channel capacity of specific obfuscation methods define strong upper limits on the amount of information that is able to pass. If an obfuscation method has capacity below the minimum requirement for differentiation of a population given the optimal distribution (uniform), it is impossible to accurately differentiate between all individuals. In practice, however, the image signal which is measured contains orders of magnitude more information, making such guarantees unlikely, at least for the methods presented in this paper. Instead, we use the measure to evaluate the relative obfuscation of information.



\subsubsection{Measuring information in images}
The term signal is rather abstract but is typically defined as a function that encodes or contains information of interest. Signals can be defined over temporal inputs, spatial inputs, or both. In the case of eye information processes, signals such as the captured eye images may be analysed individually as purely spatially divided signals or jointly as a time series of frames. The iris pattern in either its abstract or encoded form, is only resolved spatially while the gaze signal is usually analysed as a time-series. 




When viewed as bandlimited discrete signals of two dimensions, images can be analysed structurally through the 

To measure entropy and mutual information in images, it is necessary to formulate a method for defining the image in terms of a probability distribution. Specifically, it is necessary to define a model for the image distribution and estimate it using the image itself as data.

The fundamental model is that each image can be represented by an unknown distribution $P_{img}$ of an unknown number of random variables $X^1, \dots, X^n$. A simple model is the intensity histogram which estimates a discrete distribution of intensity values assuming that each pixel is independent of each other. It can be defined as
\begin{align}
    P(I=i) = \sum_{x\in\mathcal{X}y\in\mathcal{Y}} \delta_{i, I_{x,y}},
\end{align}
where $\delta_{a, b}$ is the Dirac delta function. The downside to this approach is that no correlations between pixels are considered even though they clearly exist. For use in obfuscation measurement, this is problematic since the iris recognition methods use texture and not direct pixel intensities for detection. 

In the most general terms, the distinct features of an iris pattern represents differences in the amplitude and phase of different frequencies. Many iris algorithms of the Daugman type use spatial phase responses to calculate a robust iris code. These traditional methods generally use some form of wavelet transform to separate spatial frequency-responses (REFS). The convolutional neural-network based methods likely learn similar approaches as they have been shown to learn typical bandpass-filters like the wavelets used by Daugman (REF). 

The image derivative, defined by its two partials, has excellent properties for measuring image texture complexity. The image derivative retains all information necessary to reconstruct the original image and is therefore still a valid upper bound on information measures (REF). By defining $P_{img}$ as a joint distribution of the partial derivatives of the image
\begin{align}
    P(dx=i, dy=j) = \sum_{x\in\mathcal{X}y\in\mathcal{Y}} \delta_{i, {I_{\Delta x}}_{x,y}} \delta_{j, {I_{\Delta y}}_{x,y}},
\end{align}

Additionally, we also define joint distributions on convolutions with complex Gabor wavelets. A Gabor wavelet works as a bandpass filter, i.e. it responds only to certain frequency ranges. Defining a joint distribution over the Gabor response of a particular filter makes it possible to measure the entropy in certain frequency ranges which further... By definition however, a bandpass filter does not retain all the information in the original signal and can therefore not be used for definition of upper bounds.





\section{Common reference frame}
The systems of interest in this paper are iris recognition, gaze estimation, and obviously iris obfuscation. Understanding how they are connected theoretically is critical in choosing suitable obfuscation methods and analysing the impact of the results...


\paragraph{Iris recognition}
Using the definition of an eye information system, iris recognition can be defined as the task of determining the probability of two iris codes $R^a$ and $R^b$ originating from the same source signals $Q^a = Q^b$ or different source signals $Q^a\neq Q^b$. Iris code is here used as a general term to cover any signal used for iris comparison. The probabilities are defined as $P(Q^a\neq Q^b|R^a, R^b)$, $P(Q^a\neq Q^b|R^a, R^b)$ and are determined by the comparison algorithm used. These are typically inferred by creating a distance metric $S = h(R^a, R^b)$ which is used for estimating the proxy distributions $P(S|Q^a\neq Q^b)$ or $P(S|Q^a\neq Q^b)$. In the most traditional case, iris recognition acceptance is performed by failing a statistical test of significance, i.e. determining that $P(S|Q^a\neq Q^b)$ is extremely unlikely. This was first proposed by Daugman (REF) and can be reformulated as
\begin{align}
\begin{aligned}
    h_0: & \quad s = h(R^a, R^b) &&\sim  P_{S|\hat{Q}^a\neq \hat{Q}^b}\\
    h_1: & \quad s && \sim  P_{S|\hat{Q}^a = \hat{Q}^b}.
\end{aligned}
\end{align}

In terms of the proposed eye information model, these distributions depend only on the internal system noise. 

We assume the original iris distribution to be uniform, i.e $P(Q)=1/N$ where $N$ is the total population. Given zero noise, $H(R|Q)=0$ and $H(R)=H(Q)$, $P(R)$ must be uniform on its support. As a result, $S$ which is defined to be $0$ when $R^a = R^b$, must have $P(S=0|Q^a = Q^b)=1$ and $P(S>0|Q^a \neq Q^b)=1$ since the original signals completely determine $S$. 

Because $S$ is bounded (here assumed to be normalised), an increase in noise $H(R|Q)$ increases the variance of $S$. Formally, as the noise approaches the maximum entropy of $R$, given by $M$, the distribution of $P(S)$ is
\begin{align}
\lim_{H(R|Q)\rightarrow M} P(S) = U(0, 1),
\end{align}
where $U(0, 1)$ denotes a discrete distribution of $M$ possible outcomes normalised to values in the $]0, 1[$ range. In the opposite direction, information may be lost due to low resolution image capture or bad decoding methods. This is represented by $I(R;Q)$. The relation in \autoref{eq:entropy-law} shows that mutual information limits the amount of information transmitted through the system. The limit is
\begin{align}
\lim_{I(R;Q)\rightarrow 0} P(S) = 0.
\end{align}

In other words, iris recognition systems are limited by their ability to transmit the iris pattern without introducing noise or capturing too little detail.

\paragraph{Gaze estimation}
Gaze is defined as either the direction or point of visual attention of a given subject. This property is by definition at least partially subjective, as the point of attention does not always coincide with the fovea, but instead is at least partially controllable by the subject (REF). The physical encoding of gaze is then, at least when only observing the eye's immediate position and orientation, inherently probabilistic. This is captured by the model as the distribution $P(\hat{Q}|Q_{gaze})$, if the encoding function is split between physical encoding and image capture such that $I=f_{capture}(\hat{Q})$ and $\hat{Q}=f_{physical}(Q_{gaze}, \dots)$. 

Each additional step in a given gaze estimation system introduces some amount of additional noise given by its imperfections. Robust gaze estimation can therefore be defined as transformations and decoders that have low noise-rates for large variations in signal distributions. Consequently, a non-robust system is characterised by having low noise-rates only for a narrow subset of input signals. 

%$P(I^{*1}|I^*),\dots, P(I^{*n}|I^{*(n-1)})$


\begin{align}
    \min ||Q_{gaze} - f^{gaze}_d \circ f_p^{(n)} \circ \dots \circ f_p^{(1) \circ f_e}(Q)||_2
\end{align}


\paragraph{Obfuscation}
This article's definition of iris recognition provides two paths that enable obfuscation. Increasing noise makes accurate recognition harder, while decreasing mutual information makes differentiating between irises more difficult. Artificial noise is easily added to signals using pseudo-random number generation. Mutual information decrease can be performed by either literally removing signal pieces or by using low-pass filters to remove detail. Because of the relationship between noise and mutual information (\autoref{eq:entropy-law}), adding noise also negatively affects mutual information... Thus, the expected level of obfuscation can be measured by...



To limit or prevent iris recognition, the internal noise measured as $H(R^{iris}|Q^{iris})$ should be increased towards the entropy limit. Obviously this goal is countered by the needs of gaze estimation, which require a low $H(R^{gaze}|Q^{gaze})$. Thus, obfuscation should selectively increase 

We define obfuscation as a minimisation of mutual information between the original and modified images subject to

\begin{align}
\begin{aligned}
    &\min & & \mathcal{I}(I, I^*)\\
    &\text{subject to } & &  \frac{J_{gaze}(I)}{J_{gaze}(I^*)} \leq t,\\
    \text{where:}&\\
    &&J_{gaze}(x) =& ||Q_{gaze}- f_d^{(gaze)}(x)||\\
    &&I =& \left( f_p^{(n-1)} \circ \dots \circ f_p^{(1)} \circ f_e\right) (Q)\\
    &&I^* =& f_p^{obf}(I)
\end{aligned}
\end{align}

Here, $t$ is an arbitrary threshold.

Iris recognition and gaze estimation have similar ideal physical setups. High-resolution images taken in controlled lighting conditions (typically using infrared lighting) are ideal in both cases. 

%In terms of this model, iris recognition is the process of determining whether two encoded iris signals $R^a$ and $R^b$ originate from the same source iris signal $\hat{Q}^a=\hat{Q}^b$ or from different signals $\hat{Q}^a\neq \hat{Q}^b$. Since $\hat{Q}$ cannot be known directly ($R$ is our best approximation) the goal must instead be expressed in terms of the detected iris codes. In order to provide some form of comparison, a distance function $S = h(R^a, R^b)$ is added. $P_{S|\hat{Q}^a\neq \hat{Q}^b}$ can be estimated directly from data and used in a test of statistical significance to determine whether a specific distance $s$ is unlikely to have been caused by different iris patterns. The hypothesis is




%When interpreting source and encoded iris signals as some fixed $n$-sample of probability distributions $P(Q^a)$ and $P( C^a )$ respectively, their information content is determined by the Shannon entropy measure defined as
%$$
%H(X) = -\sum_n p(x)\log_2p(x)
%$$
%This measure determines, in bits, how much information is actually present in the signal. This is important when we want to use the signals for unique identification. Assuming we can use the source iris signal $Q$, which here is defined as an abstract notion of a signal perfectly capturing the physical information in a given human iris, the average signal entropy needs to be at least 
%$$
%\frac{1}{N}\sum_{n\in \hat{Q}}H(Q^a) \geq \log_2 N
%$$
%where $N$ is the number of unique identities. Of course, it is impossible to capture $Q$ and even then the iris is still subject to small changes which adds noise. This noise may be modelled by assuming a true unchanging identity $P$ which through various physical processes result in a physical iris manifestation $Q$ as shown below:

%The source properties are encoded by $f_e$ as signals $\hat{Q}=\{Q_1, \dots, Q_n\} = f_e(q_1, \dots, q_n)$. These are captured by a camera to form the image signal $I=f_c(\hat{Q})$. An image processing function representing the obfuscation operation $I^* = f_p(I)$. The properties are then recreated by $r_i = f_d^{(i)}(I^*)$

%and $f$ is a function of $\hat{Q}$, $f(\hat{Q}) = \hat{R}$. $f$ represents the encoding, capture, and processing of the source signals. To better differentiate between the stages, we split $f$ into an encoding function $f_e$, a processing function $f_p$, and a decoding function $f_d$ such that $f=f_d\circ f_p \circ f_e$. Thus the encoding function represents both the physical manifestation of each signal as well as the camera's capture. The processing function is here used primarily to signify the obfuscation method. The decoding function then comprises everything else necessary for decoding a given signal. 


%Let an eye information processing system be defined by $\Lambda = \{\hat{Q}, \hat{R}, f\}$, where $\hat{Q}=\{Q^1, \dots, Q^n\}$ is a set of source signals, $\hat{R}=\{R^1,\dots,R^n\}$ is a set of output signals, and $f$ is a function of $\hat{Q}$, $f(\hat{Q}) = \hat{R}$. $f$ represents the encoding, capture, and processing of the source signals. To better differentiate between the stages, we split $f$ into an encoding function $f_e$, a processing function $f_p$, and a decoding function $f_d$ such that $f=f_d\circ f_p \circ f_e$. Thus the encoding function represents both the physical manifestation of each signal as well as the camera's capture. The processing function is here used primarily to signify the obfuscation method. The decoding function then comprises everything else necessary for decoding a given signal. 

%A signal represents a specific 

%The signals are random variables, instances of which are also random variables. E.g. $Q^1$ might represent an identity, $P(Q^1)$ the distribution of all identities, and $Q^1_1$ is ... 


%Images are often described as two-dimensional band-limited signals (ref). They are effectively the result of transmitting a source image signal consisting of photons over a communication channel which turns the photons into an image, i.e. a camera. In the same manner, any image manipulation is also a channel which transmits the image and possibly other signals.

%Let $\Lambda = \{\hat{Q}, \hat{O}, E, D,  f\}$ be an image communication system where $\hat{Q}$ is a set of source signals, $\hat{O}$ is a set of output signals, $E$, $D$ are encoding and decoding functions respectively, $X=E(\hat{Q})$ and $f$ is a channel which receives the encoded signal $X$ and emits $Y$.
%\begin{equation}
%    \Lambda = \{\hat{Q}, \hat{O},  \}
%\end{equation}





%To analyse the bounds on entropy necessary for accurate identification of $P$'s given $Q$'s, we need to first introduce a few notions from information theory. While entropy measures the uncertainty  in a single signal, mutual entropy $I(X, Y)$ measures the uncertainty shared between signals $X$ and $Y$. Another measure, conditional entropy $H(Y|X)$ measures the uncertainty of $Y$ after $X$ has been observed. The two measures can be defined in terms of each other $I(X, Y) = H(Y)-H(Y|X) = H(X) - H(X|Y)$. When $Y$ is produced by a communications channel from $X$, conditional entropy describes the noise added from the channel itself, while mutual information describes the entropy caused by the source signal.

%This leads to the notion of *channel capacity* which is the upper bound of mutual information through a channel for any distribution of the input signal. It is defined as
%$$
%\mathcal{C} = \sup_{p(x)} I(X, Y)
%$$
%We use a special font for $\mathcal{C}$ to distinguish it from iris code signals %$C$. For our iris recognition system we can add as a requirement that
%$$
%\frac{1}{N}\sum_{P\in\hat{P}} I(P, Q) \geq \log_2 N
%$$
%This is a tighter bound than the last one since $I(X, Y) \leq H(X)$ by the definition of mutual information.





%\subsection{Unknown}
%Look at the sample image. Features used for gaze estimation are really clear while features used for iris recognition are subtle and unpredictable. Depending on the algorithm, more than just the pupil and glints may be used for gaze estimation...



%Understanding images as bandlimited signals. We are essentially capturing an oscillating random variable which can be expressed as an infinite sum of sine waves (fourier series). This is important because it gives us more insight into what we can actually capture.

%First of all, the nyquist frequency dictates the smallest features (or frequencies) we can accurately detect - this is another way of explaining how and why image resolution matters when trying to capture a pattern (iris).

%Secondly, the features directly (or indirectly) used for gaze estimation (pupil + glints), are neither low nor high-frequency features. Instead, they look like steep, almost vertical, rises and drops, akin to square waves. As we know, these are created by adding (something) together and these features thus span the whole frequency range! This is important when choosing suitable obfuscation methods.